\section{Evaluation}
We evaluate resource adaptation via TBSM/hddRASS along several dimensions: effectiveness, usability, applicability, and scalability.

\subsection{Effectiveness}
For the \textit{Elevation API} scenario, all 4 necessary modifications were correctly performed automatically by TBSM. The development team was able to confirm the adaptations for library change by (1) examining the code for necessary modifications (2) running the tests and (3) using the application. As TSAS is a proprietary system, we have to rely on conformation from the development team. All the necessary modifications to adapt the \textit{NetBeans IDE} were also performed correctly. We observe that all 19 resource consuming statements (as identified in previous work~\cite{christi2018qrs}), the statements that fill the undo-redo buffers, were correctly modified by the technique. We have shown previously that the adapted IDE 1) cannot perform undo-redo operations and 2) uses far less memory, in a controlled experiment setting allowing only edits to a single text file~\cite{christi2017saso}. We also confirm otherwise normal operation of the IDE.

\subsection{Usability}
Most adaptation approaches require developers to learn a new specification language or add complex annotations to code. To use such techniques, developers typically need to use modeling approaches, architectural specifications, formal methods, etc., to map their application to a view that the adaptation technique supports; this is obviously a time consuming and error-prone task~\cite{salehie2009selfadaptive, krupitzer2015a}. TBSM only requires developers to look at their tests and make a ``good guess'' about the feature(s)/resource(s) relevant to each test. Developers are familiar with tests and can likely perform this task without additional training. For the \textit{NetBeans IDE} case, it took us only a few hours to determine 3 tests to label out of 146 tests, despite the fact that we are not developers, or familiar with the NetBeans code in any way before we examined it. For the \textit{Elevation API}, actual developers were almost instantly able to determine the tests pertaining to certain features.

\subsection{Applicability}
While developing the RAINBOW framework, Garlan et al. noted that most previous approaches for SASS were scenario-based or application-specific, and not very reusable~\cite{garlan2004rainbow}. To evaluate applicability, we measured the effectiveness of hddRASS as a tool. We believe hddRASS to be complete for \texttt{Java} 7: it applies to any programs written in \texttt{Java} 7. To confirm this, we checked for thrown exceptions or unprocessed statements when minimizing real-world systems. While applying hddRASS to TSAS, we processed 70 \texttt{Java} files with 338 non-constructor methods. For the \textit{NetBeans IDE}, we processed 2 \texttt{Java} files with 38 non-constructor methods. We also applied hddRASS to 40 randomly selected classes with a total of 1,207 methods across 10 open source projects, using a random labeling scheme~\cite{christi2018qrs}. We observed neither exceptions nor unprocessed statements across these experiments. Based on this, we can say that hddRASS as a tool, and TBSM as a technique, is generally applicable to \texttt{Java} applications. To extend it to other programming language, one needs to build hddRASS like tool for that programming language.    

\subsection{Scalability}
For the \textit{Elevation API} the application of hddRASS, using no heuristics, on all 70 Javafiles took 7 hours and 50 minutes. For \textit{NetBeans IDE}, adapting two files in \texttt{openide.awt} using no heuristics took 2 hours and 35 minutes. As the program size increases or test suite runtime increases, scalability becomes the limiting factor in TBSM. For offline adaptations, scalability may not be a limiting factor. But for live systems deployed in the wild, the system needs to be halted until adaptations are performed and a long offline period is not normally acceptable.  The speed of the most thorough version of TBSM without heuristics to guide adaptation is likely acceptable for use before deployment, e.g., to prepare a specialized version of a system for a resource-limited platform, but unsuitable for field use.  However, as we discuss below, even without additional developer effort, use of heuristics to compute approximate or incremental best-effort adaptations can mitigate this problem substantially.

