\section{Challenges}
We describe the major challenges that we faced while applying TBSM to build real-world RASS, and how we attempted to solve these challenges for the case study scenarios. In the process, we identify major research challenges in TBSM. We note the similarity between the challenges in TBSM and the challenges observed by researchers in APR~\cite{LeGoues2013}.

\subsection{Search Space}
TBSM indiscriminately processes all the statements of a program, so the search space is accordingly vast. This can be significantly reduced by selecting only statements likely to actually be modified. We empirically evaluated a large number of adaptation related modification for 800 synthetic adaptations to derive heuristics to guide target selection. We derived statistics-based heuristics (H1, H2) and dynamic-analysis-based heuristics (CBLS, AdFL) based on our evaluation~\cite{christi2018qrs,christi2019qrs}. The CBLS heuristic relies on coverage information for thelabeled and unlabeled test suite. We repurpose Spectrum-Based Fault Localization (SBFL) to derive the more general AdFL heuristic by establishing equivalence between core components of SBFL and core components of TBSM. We found that dynamic-analysis-based heuristics  perform better in empirical analysis. For the \textit{Elevation API} scenario, CBLS reduces the search space by 55\% and AdFL heuristics reduces search space by 92\% bringing the wall clock time to build adaptations down from 460 minutes to 118 minutes for CBLS and 49 minutes for AdFL.  For the \textit{NetBeans IDE} scenario, CBLS heuristics reduces search space by 90\% and AdFL heuristics reduces search space by 94\% bringing the wall clock time down from 175 minutes to 61 minutes and 57 minutes for CBLS and AdFL respectively. 

The CBLS heuristics provides search space reduction while AdFL prioritizes the search space based on likeliness of modification. We demonstrated that the likely targets of modifications would appear earlier in the sorted order if we use AdFL~\cite{christi2019qrs}. We used this fact to circumvent the search space issue all together. We proposed best-effort incremental TBSM as a technique were developers provide a time limit to finish the adaptations~\cite{christi2019qrs}. The best-effort incremental TBSM will always produce a useable system in the given amount of time, with resource adaptation achieved entirely or partially. For \textit{Elevation API} and \textit{NetBeans IDE} scenarios, time limits of 35 minutes and 20 minutes, respectively, were sufficient to perform complete resource adaptation using best-effort incremental TBSM. Best-effort incremental TBSM performs better than AdFL heuristics with 90\% search space reduction for both scenarios. 

\subsection{Test Suite Runtime }
Like APR, TBSM is a generate-and-validate technique that must execute a potentially large test suite to evaluate each modification. TBSM benefits from a large test suite, but running all tests is often prohibitively slow. The version of \textit{NetBeans IDE} we used has a test suite that requires 7+ hours to run for all 1193 modules. TSAS also exhibits unacceptably slow complete test suite runtime. For both case studies, we observe that running only modified-module-related tests is sufficient, as modules are self-contained and have good individual test suites. We observe that even such a simple ad-hoc test selection reduces test runtime to 34 seconds and 18 seconds for the \textit{NetBeans IDE} and \textit{Elevation API}, respectively. For most resource adaptation scenarios, such an ad-hoc technique is not feasible and scalable. We need test selection and prioritization (since early failures also limit runtime) tailored to TBSM.

\subsection{Inefficient Algorithm}
Our hddRASS reducer uses a modified HDD$^*$ algorithm with worst-case running time of $O(n^3)$, where $n$ in our case is the number of statement nodes of the abstract syntax tree of the program~\cite{misherghi2006hdd}. We employ HDD$^*$ as the underlying driver for TBSM because it guarantees convergence and minimality. By minimality, we mean that any output program produced by TBSM is minimal and cannot be modified any further. One solution we employ is to forgo the minimality guarantee of HDD$^*$ and use a pure greedy search, trading accuracy for efficiency.  With a greedy search strategy, we can build resource adaptations 1.72 times faster while retaining 94\% accuracy for the \textit{Elevation API} and 1.90 times faster while retaining 100\% accuracy for \textit{NetBeans IDE}. We need further evaluation of different search strategies and heuristics-based modifications to HDD$^*$.

\subsection{Overfitting}
The issue of overfitting is well studied in APR, and we face the same problem\cite{smith2015cwd}. TBSM produces test-adequate adaptations, adaptations that are correct with respect to a test suite and test labeling scheme. For our case studies, Type 1 errors are rare, and even related statements are usually removed; e.g., if a single resource consuming statement is the body of a for loop, the loop is removed as well. We consider directly or indirectly resource-adaptation-related modifications as correct modifications. We do observe a large number of false modifications, modifications that are not directly or indirectly related to resource adaptations: these are the more common Type 2 errors. Indeed, the false modifications outnumber true ones in our scenarios. A total of 49 and 121 modifications are performed by TBSM for the \textit{Elevation API} and \textit{NetBeans IDE} scenarios, respectively. We observe 91\% and 51\% false modification rates for the \textit{Elevation API} and \textit{NetBeans IDE} adaptations, respectively. As TBSM generated test-adequate adaptations overfit a given test suite and labeling scheme, TBSM is vulnerable to both (1) inadequacy of the test suite and (2) labeling errors. Developers reported instances where TBSM-generated modifications removed untested but desired functionality. 
