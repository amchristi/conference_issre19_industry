\section{Ongoing Work and Future Directions}
As part of DARPA BRASS project, we work with multiple software development teams and other collaborators. Our communication with these stakeholders as well as the feedback that we received from the development teams using our work are driving our ongoing efforts.
\subsection{Ongoing Work}
\subsubsection{Improving Applicability}
The underlying tool hddRASS that drives TBSM only supports Java. Raytheon development team uses TBSM for TSAS, an application written in Java.  We also developed, and plan to release in the near future, a C++ version of hddRASS.  We developed it specifically for use by ROS (Robotics Operating System) application developers to adapt against ROS version changes and other ROS package changes, but it can be applied to any C++ code base.

\subsubsection{Minimization vs. Modification}
One core current limitation of TBSM is that it only offers minimization (reduction), rather than code \emph{modification}. Adaptation, however, can generally include (1) reduction, (2) replacement, and (3) enhancement~\cite{hughes2016building}. The published TBSM version only supports reduction. While developing the C++ version of hddRASS, we incorporated many modification operators from APR used to fix faults, making some replacement capabilities available~\cite{Forrest2009genetic,Arcuri2009phdthesis,Debroy2010using}. We plan to continue to improve hddRASS to provide more modification capabilities. 

\subsection{Future Directions}
We are currently investigating multiple other ways to speed up TBSM, including using static and dynamic analysis to precompute the effects of program statements on test oracles and using test case selection and prioritization to reduce the running time of tests in TBSM’s generate-and-validate loop.

The original work in TBSM emphasized the need for a ``good'' test suite. Previous heuristics suggested coverage as a way to define “goodness” of a test suite; the CBLS heuristic depends on coverage information. Because of the success of AdFL heuristics in isolating and prioritizing modification targets, we plan to consider test suite diagnosability metrics as a more refined way to define the “goodness” of a test suite for TBSM, using approaches proposed by Baudry et al. and Perez et al.~\cite{Baudry2006improving,perez2017diagnosibility}

For our work, we mostly used existing test suites provided by the developers. As discussed above, sometimes a test that a developer labeled as pertaining to onefeature may contain code that exercises other features. Similarly, an unlabeled test, apart from testing functionality that needs to be retained, may exercise sacrificial features.  Presence of such tests makes it harder for TBSM to differentiate between an adaptation-related modification and an accidental modification, resulting in underfitting or overfitting. To mitigate the situation, we plan to extend work on test-case purification~\cite{xuan2014test}  and test-case decomposition~\cite{stvrcausereduce,christi18reduce} to \emph{automatically produce more fine-grained tests}, and ideally, automatically label them.
